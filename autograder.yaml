# Version format ex. "0.0.1"
version: "0.1.16"                            # Flow specification version

# Basic metadata for the agent
metadata:
  name: "auto-grader"                               # Unique identifier
  description: "This flow will help teachers to quickly and accurately grade assignments"       # Flow purpose
  author: "amay"                              # Must match your account username
  tags: [education]                       # Keywords for categorization
  private: false                                       # Access control setting

# Define the input variables required
inputs:
  input1:                                              # First input parameter
    type: string                                       # Currently only String format
    description: "Model Questions and Answers on which we Grade the Submissions"
    required: true
    example: "Example value for input1"
  input2:                                              # Second input parameter
    type: string
    description: "Actual answers given by students"
    required: true
    example: "Example value for input2"

# LLM configuration
model:
  provider: "openai"                            # e.g., anthropic, openai, meta, etc.
  name: "gpt-4o"                                   # Specific model identifier

  # Make sure this dataset exists

# Prompt template configuration
prompt: |
  You are an expert grading assistant. Your task is to evaluate student answers based on how closely they match the model answers. Here are the inputs:

  1. **{input1}**: A set of questions along with their model answers and the maximum marks for each question.  
  2. **{input2}**: A set of answers provided by a student for the same questions.

  Your task is:  
  1. For each question, compare the student's answer with the model answer.  
  2. Allot marks to the student's answer based on how closely it matches the model answer.  
  3. Ensure the marks are fair and proportional to the quality of the answer.  
  4. Do not answer the questions yourselfâ€”only evaluate the student's answers.  
  5. Keep track of which question is being evaluated to avoid confusion.  

  Output format:  
  1. For each question, display:  
    - Question number  
    - Marks allotted (out of the maximum marks for that question)  
    - A brief explanation of why the marks were allotted (e.g., "The answer was partially correct but missed key details.") 
    - Leave a line after each question. 
  2. At the end, display the total marks obtained by the student.  

  Example:  
  Input 1:  
  Q1: What is AI? (Model Answer: AI stands for Artificial Intelligence. It is the simulation of human intelligence in machines. Max Marks: 5)  
  Q2: What are the applications of AI? (Model Answer: AI is used in healthcare, autonomous vehicles, and virtual assistants. Max Marks: 10)  

  Input 2:  
  Q1: AI is Artificial Intelligence. It makes machines smart.  
  Q2: AI is used in cars and phones.  

  Output:  
  Q1: Marks allotted: 4/5  
  Explanation: The student correctly defined AI but missed the detail about simulating human intelligence.  

  Q2: Marks allotted: 6/10  
  Explanation: The student mentioned two applications (cars and phones) but missed healthcare and did not provide sufficient detail.  

  Total Marks: 10/15  

  Now, evaluate the following:  
  {input1}  
  {input2}  

  

# ReadME configuration
readme: |
  Your flow's readme...
  You can use raw text or markdown here.